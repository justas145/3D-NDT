{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all the necessary libraries\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import Augmentor\n",
    "import glob\n",
    "import shutil\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import itertools\n",
    "import keras\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, LeakyReLU, Dense, Dropout, Flatten, MaxPool2D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a list of image names with plf error\n",
    "plf_image_names = []\n",
    "with open(\"yz_labels_newest.txt\") as f:\n",
    "    for line in f:\n",
    "        file, label = line.strip('\\n').split(\": \")\n",
    "        if label != \"0\":\n",
    "            plf_image_names.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy pasting images with plf to another folder for data augmentation\n",
    "src_dir = \"Processed_Images_YZ\"\n",
    "dst_dir = \"plf_YZ\"\n",
    "for jpgfile in glob.iglob(os.path.join(src_dir, \"*.jpg\")):\n",
    "    if jpgfile.replace(\"Processed_Images_YZ\\\\\", \"\") in plf_image_names:\n",
    "        shutil.copy(jpgfile, dst_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passing the path of the image directory (augmented images created from images with plf in this folder are deleted)\n",
    "p = Augmentor.Pipeline(\"Processed_Images_YZ\")\n",
    "# Defining augmentation parameters and generating 500 image samples with no errors\n",
    "p.zoom(probability=0.95, min_factor=0.8, max_factor=1.2)\n",
    "p.rotate(probability=0.95, max_left_rotation=10, max_right_rotation=10)\n",
    "p.skew_corner(probability=0.8)\n",
    "p.flip_left_right(probability=0.95)\n",
    "p.sample(500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passing the path of the image directory\n",
    "p = Augmentor.Pipeline(\"plf_YZ\")\n",
    "# Defining augmentation parameters and generating 1000 image samples with plf errors\n",
    "p.zoom(probability=0.95, min_factor=0.8, max_factor=1.2)\n",
    "p.rotate(probability=0.95, max_left_rotation=10, max_right_rotation=10)\n",
    "p.skew_corner(probability=0.8)\n",
    "p.flip_left_right(probability=0.95)\n",
    "p.sample(1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting a list of augmented image names with plf error\n",
    "mypath = 'plf_YZ\\output'\n",
    "augmented_images_plf = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting a list of augmented image names with no error\n",
    "mypath2 = 'Processed_Images_YZ\\output'\n",
    "augmented_images_no_error = [f for f in listdir(\n",
    "    mypath2) if isfile(join(mypath2, f))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function that appends to the lists a label, image name and image in grayscale\n",
    "def load_images_yz(folder, image_dir, images_name, images, labels, crop=False, list=False, error=False):\n",
    "    if list == True:\n",
    "        if error == True:\n",
    "            label = '1'\n",
    "        elif error == False:\n",
    "            label = '0'\n",
    "        for file in folder:\n",
    "            # read the image Processed_Images_XZ\\output\\\n",
    "            image = cv2.imread(f\"{image_dir}{file}\")\n",
    "            # resize to 224 x 224\n",
    "            if crop:\n",
    "                image = cv2.resize(image, (224, 224))\n",
    "\n",
    "            # from BGR to gray\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # append image and label to the list\n",
    "            images_name.append(f\"{image_dir}{file}\")\n",
    "            images.append(image)\n",
    "            labels.append(label)\n",
    "        return images, labels, images_name\n",
    "    with open(folder) as f:\n",
    "        for line in f:\n",
    "            # get the path of an image and the label\n",
    "            file, label = line.strip(\"\\n\").split(\": \")\n",
    "\n",
    "            # read the image\n",
    "            image = cv2.imread(f\"{image_dir}{file}\")\n",
    "\n",
    "            # resize to 224 x 224\n",
    "            if crop:\n",
    "                image = cv2.resize(image, (224, 224))\n",
    "\n",
    "            # from BGR to gray\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # append image and label to the list\n",
    "            images_name.append(f\"{image_dir}{file}\")\n",
    "            images.append(image)\n",
    "            labels.append(label)\n",
    "        return images, labels, images_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_name, images, labels = [], [], []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading in the images and labels\n",
    "images, labels, images_name = load_images_yz(\n",
    "    \"yz_labels_newest.txt\",\"Processed_Images_YZ/\",  images_name, images, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels, images_name = load_images_yz(\n",
    "    augmented_images_plf, \"plf_YZ/output/\",  images_name, images, labels, list=True, error=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels, images_name = load_images_yz(\n",
    "    augmented_images_no_error, \"Processed_Images_YZ/output/\", images_name, images, labels, list=True, error=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalise and transform to np array\n",
    "def normalise_images(images, labels):\n",
    "    # Convert to numpy arrays\n",
    "    images = np.array(images, dtype=np.float32)\n",
    "    labels = np.array(labels)\n",
    "    labels = labels.astype(np.int)\n",
    "    # 0: no error, 1: plf error\n",
    "    labels[labels == 2] = 1\n",
    "    # Normalise the images\n",
    "    images /= 255.0\n",
    "\n",
    "    return images, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_norm, labels = normalise_images(images, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking if the numbers are correct\n",
    "unique_labels, counts_labels = np.unique(labels, return_counts=True)\n",
    "print(np.asarray((unique_labels, counts_labels)).T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle the data\n",
    "def shuffle_data(images_norm, labels, images_name):\n",
    "    X_data, y_data, images_name = sklearn.utils.shuffle(\n",
    "        images_norm, labels, images_name, random_state=42)\n",
    "\n",
    "    return X_data, y_data, images_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data, y_data, images_name = shuffle_data(\n",
    "    images_norm, labels, images_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshaping\n",
    "X_data = X_data.reshape(-1, X_data.shape[1], X_data.shape[2], 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoder, e.g.: if it is a plf then y=[0, 1]\n",
    "y_data = to_categorical(y_data, num_classes=len(np.unique(y_data)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the graph down below decide on the epochs\n",
    "epochs_light = 30\n",
    "epochs_heavy = 20\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 70-30 train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_data, y_data, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# buildiing light CNN model\n",
    "yz_model_light = Sequential()\n",
    "yz_model_light.add(Conv2D(2, kernel_size=(3, 3), activation='linear',\n",
    "                       input_shape=(X_data.shape[1], X_data.shape[2], 1), padding='same'))\n",
    "yz_model_light.add(LeakyReLU(alpha=0.1))\n",
    "yz_model_light.add(MaxPooling2D((2, 2), padding='same'))\n",
    "yz_model_light.add(Conv2D(4, (3, 3), activation='linear', padding='same'))\n",
    "yz_model_light.add(LeakyReLU(alpha=0.1))\n",
    "yz_model_light.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
    "yz_model_light.add(Conv2D(4, (3, 3), activation='linear',\n",
    "                    padding='same', name='just_do_it'))\n",
    "yz_model_light.add(LeakyReLU(alpha=0.1))\n",
    "yz_model_light.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
    "yz_model_light.add(Flatten())\n",
    "yz_model_light.add(Dense(2, activation='linear'))\n",
    "yz_model_light.add(LeakyReLU(alpha=0.1))\n",
    "yz_model_light.add(Dense(y_data.shape[1], activation='softmax'))\n",
    "\n",
    "# Compiling the model\n",
    "yz_model_light.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                 optimizer=tf.keras.optimizers.Adam(), metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving untrained light model for later use\n",
    "yz_model_light.save(\"yz_model_light_untrained.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building heavy CNN model \n",
    "yz_model_heavy = Sequential()\n",
    "yz_model_heavy.add(Conv2D(8, kernel_size=(3, 3), activation='linear',\n",
    "                      input_shape=(X_data.shape[1], X_data.shape[2], 1), padding='same'))\n",
    "yz_model_heavy.add(LeakyReLU(alpha=0.1))\n",
    "yz_model_heavy.add(MaxPooling2D((2, 2), padding='same'))\n",
    "yz_model_heavy.add(Conv2D(16, (3, 3), activation='linear', padding='same'))\n",
    "yz_model_heavy.add(LeakyReLU(alpha=0.1))\n",
    "yz_model_heavy.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
    "yz_model_heavy.add(Conv2D(32, (3, 3), activation='linear',\n",
    "                      padding='same', name=\"just_do_it\"))\n",
    "yz_model_heavy.add(LeakyReLU(alpha=0.1))\n",
    "yz_model_heavy.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
    "yz_model_heavy.add(Flatten())\n",
    "yz_model_heavy.add(Dense(16, activation='linear'))\n",
    "yz_model_heavy.add(LeakyReLU(alpha=0.1))\n",
    "yz_model_heavy.add(Dense(y_data.shape[1], activation='softmax'))\n",
    "\n",
    "yz_model_heavy.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                   optimizer=tf.keras.optimizers.Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving untrained heavy model for later use\n",
    "yz_model_heavy.save(\"yz_model_heavy_untrained.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training light model\n",
    "history_light = yz_model_light.fit(X_train, y_train, epochs=epochs_light,\n",
    "                                   batch_size=batch_size, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training heavy model\n",
    "history_heavy = yz_model_heavy.fit(X_train, y_train, epochs=epochs_heavy,\n",
    "                                   batch_size=batch_size, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_vs_performance_plot(history):\n",
    "    # Plot the loss and accuracy curves for training and validation\n",
    "    fig, ax = plt.subplots(2, 1)\n",
    "    ax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\n",
    "    ax[0].plot(history.history['val_loss'], color='r',\n",
    "            label=\"validation loss\", axes=ax[0])\n",
    "    ax[1].set_xlabel(\"Number of epochs\")\n",
    "    legend = ax[0].legend(loc='best', shadow=True)\n",
    "\n",
    "    ax[1].plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\n",
    "    ax[1].plot(history.history['val_accuracy'],\n",
    "            color='r', label=\"Validation accuracy\")\n",
    "    ax[1].set_xlabel(\"Number of epochs\")\n",
    "    legend = ax[1].legend(loc='best', shadow=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_vs_performance_plot(history_light)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_vs_performance_plot(history_heavy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deciding on epochs from the graph\n",
    "epochs_light = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deciding on epochs from the graph\n",
    "epochs_heavy = 13 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speed_and_acc(model, X_test, y_test):\n",
    "    start_time = time.time()\n",
    "    test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "    delta_time = time.time() - start_time\n",
    "    num_img = X_test.shape[0]\n",
    "    print(\"--- %s images per second ---\" % (num_img/delta_time))\n",
    "    print(f\"test acc: {test_acc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load untrained heavy model\n",
    "yz_model_heavy = keras.models.load_model('yz_model_heavy_untrained.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train heavy model with new epochs number\n",
    "history_heavy = yz_model_heavy.fit(X_train, y_train, epochs=epochs_heavy,\n",
    "                                   batch_size=batch_size, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check speed and accuracy of the heavy model on the test set\n",
    "speed_and_acc(yz_model_heavy, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load untrained light model\n",
    "yz_model_light = keras.models.load_model('yz_model_light_untrained.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train light model with new epochs number\n",
    "history_light = yz_model_light.fit(X_train, y_train, epochs=epochs_light,\n",
    "                                   batch_size=batch_size, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check speed and accuracy of the light model on the test set\n",
    "speed_and_acc(yz_model_light, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting confusion matrix\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the values from the test set on the light model\n",
    "Y_pred = yz_model_light.predict(X_test)\n",
    "# Convert predictions classes to one hot vectors\n",
    "Y_pred_classes = np.argmax(Y_pred, axis=1)\n",
    "# Convert validation observations to one hot vectors\n",
    "Y_true = np.argmax(y_test, axis=1)\n",
    "# compute the confusion matrix\n",
    "confusion_mtx = confusion_matrix(Y_true, Y_pred_classes)\n",
    "# plot the confusion matrix\n",
    "plot_confusion_matrix(confusion_mtx, classes=[\"No error\", \"PLF\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the values from the test set on the heavy model\n",
    "Y_pred = yz_model_heavy.predict(X_test)\n",
    "# Convert predictions classes to one hot vectors\n",
    "Y_pred_classes = np.argmax(Y_pred, axis=1)\n",
    "# Convert validation observations to one hot vectors\n",
    "Y_true = np.argmax(y_test, axis=1)\n",
    "# compute the confusion matrix\n",
    "confusion_mtx = confusion_matrix(Y_true, Y_pred_classes)\n",
    "# plot the confusion matrix\n",
    "plot_confusion_matrix(confusion_mtx, classes=[\"No error\", \"PLF\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading untrained light model\n",
    "yz_model_light = keras.models.load_model('yz_model_light_untrained.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training light model on full dataset\n",
    "yz_model_light.fit(X_data, y_data, epochs=epochs_light,\n",
    "                   batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving final light yz model\n",
    "yz_model_light.save(\"yz_model_light_FINAL.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading untrained light model\n",
    "yz_model_heavy = keras.models.load_model('yz_model_heavy_untrained.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training heavy model on full dataset\n",
    "yz_model_heavy.fit(X_data, y_data, epochs=epochs_heavy,\n",
    "                   batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving final light yz model\n",
    "yz_model_heavy.save(\"yz_model_heavy_FINAL.h5\")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1b6f61127302c8e325fb6b7b2a15bdad1f74708faa59b57333af7291771c5326"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('tf_cpu': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
